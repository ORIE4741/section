{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 10 Causal Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This material is based on the [`blog`](http://www.degeneratestate.org/index.html) by Iain Barr. We will use the excellent [`CausalInference`](http://causalinferenceinpython.org/) package to give an overview of how we can use the [potential outcomes](https://en.wikipedia.org/wiki/Rubin_causal_model) framework to try and make causal inferences about situations where we only have observational data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import datagenerators as dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "One day a team lead notices that some members of their team wear cool hats, and that these members of the team tend to be less productive. Being data drive, the Team Lead starts to record whether or not a team member wears a cool hat ($X=1$ for a cool hat, $X=0$ for no cool hat) and whether or not they are productive ($Y=1$ for productive, $Y=0$ for unproductive).\n",
    "\n",
    "After making observations for a week, they end up with a dataset like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_data_0 = dg.generate_dataset_0()\n",
    "\n",
    "observed_data_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first question the team lead asks is: are people wearing cool hats more likely to be productive that those who don't? This means estimating the quantity\n",
    "\n",
    "$\\Delta = P(Y=1|X=1) - (Y=1|X=0),$\n",
    "\n",
    "which we can do directly from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_uplift(ds):\n",
    "    \"\"\"\n",
    "    Estiamte the difference in means between two groups.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: pandas.DataFrame\n",
    "        a dataframe of samples.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    estimated_uplift: dict[Str: float] containing two items:\n",
    "        \"estimated_effect\" - the difference in mean values of $y$ for treated and untreated samples.\n",
    "        \"standard_error\" - 90% confidence intervals arround \"estimated_effect\"\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    base = ds[ds.x == 0]\n",
    "    variant = ds[ds.x == 1]\n",
    "    \n",
    "    delta = \n",
    "    delta_err = \n",
    "    \n",
    "    return {\"estimated_effect\": delta, \"standard_error\": delta_err}\n",
    "\n",
    "estimate_uplift(observed_data_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you infer from the experiment above?\n",
    "\n",
    "To be sure, we can even run a statistical test to find the p value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = (\n",
    "    observed_data_0\n",
    "    .assign(placeholder=1)\n",
    "    .pivot_table(index=\"x\", columns=\"y\", values=\"placeholder\", aggfunc=\"sum\")\n",
    "    .values\n",
    ")\n",
    "\n",
    "\n",
    "# calculate p-value using chi2_contingency\n",
    "\n",
    "\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the p value small?\n",
    "\n",
    "We can use this information to make statements about what we might think about someone's probability if we see them wearing a cool hat. As long as we believe that they are \"drawn from the same distribution\" as our previous observations, we expect the same correlations to exist. \n",
    "\n",
    "The problem comes if we try to use this information as an argument about whether or not the team lead should **force** people to wear cool hats. If the team lead does this they fundamentally change the system we are sampling from, potentially altering or even reversing any correlations we observed before.\n",
    "\n",
    "The cleanest way to actually measure the effect of some change in a system is by running a [randomized control trial](https://en.wikipedia.org/wiki/Randomized_controlled_trial). Specifically, we want to randomize who gets cool hats and who doesn't, and look at the different values of $y$ we receive. This removes the effect of any [confounding variables](https://en.wikipedia.org/wiki/Confounding) which might be influencing the metric we care about.\n",
    "\n",
    "Because we generated our dataset from a known process, we can intervene in it directly and measure the effect of an A/B test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ab_test(datagenerator, n_samples=10000, filter_=None):\n",
    "    \"\"\"\n",
    "    Generates n_samples from datagenerator with the value of X randomized\n",
    "    so that 50% of the samples recieve treatment X=1 and 50% receive X=0,\n",
    "    and feeds the results into `estimate_uplift` to get an unbiased \n",
    "    estimate of the average treatment effect.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    effect: dict\n",
    "    \"\"\"\n",
    "    n_samples_a = \n",
    "    n_samples_b = \n",
    "    set_X = \n",
    "    ds = datagenerator(n_samples=n_samples, set_X=set_X)\n",
    "    if filter_ != None:\n",
    "        ds = ds[filter_(ds)].copy()\n",
    "    return estimate_uplift(ds)\n",
    "\n",
    "run_ab_test(dg.generate_dataset_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude from the new experiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions of Causality \n",
    "\n",
    "The previous example demonstrates the old statistics saying: \n",
    "\n",
    "[**Correlation Does Not Imply Causation**](https://xkcd.com/552/).\n",
    "\n",
    "[\"Causality\"](https://plato.stanford.edu/entries/causation-metaphysics/) is a vague, philosophical sounding word. In the current context, I am using it to mean \"What is the effect on $Y$ of changing $X$?\"\n",
    "\n",
    "To be precise, $X$ and $Y$ are [random variables](http://mathworld.wolfram.com/RandomVariable.html) and the \"effect\" we want to know is how the distribution of $Y$ will change when we force $X$ to take a certain value. This act of forcing a variable to take a certain value is called an \"Intervention\".\n",
    "\n",
    "In the previous example, when we make no intervention on the system, we have an observational distribution of $Y$, conditioned on the fact we observe $X$:\n",
    "\n",
    "$P(Y|X)$\n",
    "\n",
    "When we force people to wear cool hats, we are making an intervention. The distribution of $Y$ is then given by the _interventional_ distribution \n",
    "\n",
    "$P(Y|\\hbox{do}(X))$\n",
    "\n",
    "In general these two are not the same.\n",
    "\n",
    "The question these notes will try and answer is how we can reason about the interventional distribution, when we only have access to observational data. This is a useful question because there are lots of situations where running an A/B test to directly measure the effects of an intervention is impractical, unfeasable or unethical. In these situations we still want to be able to say something about what the effect of an intervention is - to do this we need to make some assumptions about the data generating process we are investigating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Outcomes \n",
    "\n",
    "One way to approach this problem is to introduce two new random variables to our system: $Y_{0}$ and $Y_{1}$, known as the [Potential Outcomes](http://www.stat.unipg.it/stanghellini/rubinjasa2005.pdf). We imagine that these variables exist, and can be treated as any other random variable - the only difference is that they are never directly observed. $Y$ is defined in terms of \n",
    "\n",
    " - $Y = Y_{1}$ when $X=1$\n",
    " - $Y = Y_{0}$ when $X=0$\n",
    " \n",
    "This shifts the problem from one about how distributions change under the intervention, to one about data drawn i.i.d. from some underlying distribution with [missing values](https://en.wikipedia.org/wiki/Missing_data). Under certain assumptions about why values are missing, there is well developed theory about how to estimate the missing values.\n",
    "\n",
    "# Goals\n",
    "\n",
    "Often we do not care about the full interventional distribution, $P(Y|\\hbox{do}(X))$, and it is enough to have an estimate of the difference in means between the two groups. This is a quantity known as the [Average Treatment Effect](https://en.wikipedia.org/wiki/Average_treatment_effect):\n",
    "\n",
    "$\\Delta = E[Y_{1} - Y_{0}]$\n",
    "\n",
    "When we run and A/B test and compare the means of each group, this is directly the quantity we are measuring \n",
    "\n",
    "If we just try and estimate this quantity from the observational distribution, we get:\n",
    "\n",
    "$\\Delta_{bad} = E[Y|X=1] - E[Y|X=0] \\\\\n",
    "= E[Y_{1}|X=1] - E[Y_{0}|X=0] \\\\\n",
    "\\neq \\Delta$\n",
    "\n",
    "This is not generally equal to the true ATE because:\n",
    "\n",
    "$E[Y_{i}|X=i] \\neq E[Y_{i}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\def\\ci{\\perp\\!\\!\\!\\perp}$\n",
    "# Making Assumptions\n",
    "\n",
    "When we A/B test, we randomize the assignment of $X$. This has the effect of allowing us to choose which variable of $Y_{1}$ or $Y_{0}$ is revealed to us. This makes the outcome independent of the value of $X$. We write this as\n",
    "\n",
    "$Y_{1}, Y_{0} \\ci X$\n",
    "\n",
    "Which means that the distribution of $X, Y_{0}, Y_{1}$ factorizes as\n",
    "\n",
    "$P(X, Y_{0}, Y_{1}) = P(X)P(Y_{0}, Y_{1})$\n",
    "\n",
    "If this independence holds then\n",
    "\n",
    "$E[Y_{1}|X=1] = E[Y_{1}]$\n",
    "\n",
    "If we want to estimate the ATE using observational data, we need to use other information we have about the samples - specifically we need to **assume** that we have enough additional information to completely explain the choice of treatment each subject.\n",
    "\n",
    "If we call the additional information the random variable $Z$, we can write this assumption as\n",
    "\n",
    "$Y_{1}, Y_{0} \\ci X \\, | \\, Z$\n",
    "\n",
    "or\n",
    "\n",
    "$P(X, Y_{0}, Y_{1}| Z) = P(X|Z)P(Y_{0}, Y_{1}|Z)$\n",
    "\n",
    "This means that the observed treatment a sample receives, $X$, is completely explained by $Z$. This is sometimes called the [\"ignorability\" assumption](https://en.wikipedia.org/wiki/Ignorability).\n",
    "\n",
    "In our motivating example about cool hats this would mean that there is some other factor - let's call it \"skill\" - which impacts both the productivity of the person and whether or not they wear a cool hat. In our example above, skilled people are more likely to be productive and also less likely to were cool hats. These facts together _could_ explain why the effect of cool hats seemed to reverse when ran an A/B test. \n",
    "\n",
    "If we split our data on whether or not the person is skilled, we find that for each subgroup there is a positive relationship between wearing cool hats and productivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_data_0_with_confounders = dg.generate_dataset_0(show_z=True)\n",
    "\n",
    "print(estimate_uplift(observed_data_0_with_confounders.loc[lambda df: df.z == 0]))\n",
    "print(estimate_uplift(observed_data_0_with_confounders.loc[lambda df: df.z == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortuntly, because we never observe $Y_{0}$ and $Y_{1}$ for the same sample, we cannot test the assumption that \n",
    "\n",
    "$Y_{1}, Y_{0} \\ci X \\, | \\, Z$\n",
    "\n",
    "It is something we have to use our knownledge of the system we are investigating to evaluate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Counterfactual\n",
    "\n",
    "From the above, it should be clear that if know $Y_{0}$ and $Y_{1}$, we can estimate the ATE. So why not just try and model them directly? Specifically we can build estimators: \n",
    " \n",
    " - $\\hat{Y}_{0}(Z) = E[Y|Z, X=0]$\n",
    " - $\\hat{Y}_{1}(Z) = E[Y|Z, X=1]$. \n",
    " \n",
    "If we can model these two quantities, we can estimate the ATE as:\n",
    "\n",
    "$\\Delta = \\frac{1}{N}\\sum_{i}(\\hat{Y}_{1}(z_{i}) - \\hat{Y}_{0}(z_{i}))$\n",
    "\n",
    "The success of this approach depends on how well we can model the potential outcomes. To see it in action, let's use the following data generating process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_data_1 = dg.generate_dataset_1()\n",
    "\n",
    "observed_data_1.plot.scatter(x=\"z\", y=\"y\", c=\"x\", cmap=\"rainbow\", colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into modelling the counterfactual, let's look at the data. If we look at how $Y$ is distributed, there appears to be a small difference between the two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(observed_data_1.loc[lambda df: df.x == 0].y, label=\"untreated\")\n",
    "sns.kdeplot(observed_data_1.loc[lambda df: df.x == 1].y, label=\"treated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm this by looking at the difference in means between the two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observed ATE: {estimated_effect:.3f} ({standard_error:.3f})\".format(**estimate_uplift(observed_data_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we look at the distribution of the covariance, $Z$, it is clear that there is a difference between the groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(observed_data_1.loc[lambda df: df.x == 0].z, label=\"untreated\")\n",
    "sns.kdeplot(observed_data_1.loc[lambda df: df.x == 1].z, label=\"treated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we believe that $Z$ has some infulance on the metric $Y$, this should concern us. We need some way to disentangle the effect of $X$ on $Y$ and the effect of $Z$ on $Y$.\n",
    "\n",
    "We can check the actually ATE using our simulated A/B test and confirm that it is difference of the observed value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real ATE:  {estimated_effect:.3f} ({standard_error:.3f})\".format(**run_ab_test(dg.generate_dataset_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens if we cannot run this A/B test? We need to resort to modelling the system.\n",
    "\n",
    "The simplest type of model we can use is a linear model. Specifically we could assume \n",
    "\n",
    "$Y_{0} = \\alpha + \\beta Z + \\epsilon$\n",
    "\n",
    "$Y_{1} = Y_{0} + \\gamma$\n",
    "\n",
    "If this is accurate, fitting the model\n",
    "\n",
    "$Y = \\alpha + \\beta Z + \\gamma X$\n",
    "\n",
    "to the data using linear regression will give us an estimate of the ATE.\n",
    "\n",
    "The `causalinference` package gives us a simple interface to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalinference import CausalModel\n",
    "\n",
    "cm = CausalModel(\n",
    "    \n",
    "\n",
    "\n",
    "                )\n",
    "\n",
    "cm.est_via_ols(adj=1)\n",
    "\n",
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`causalinference` returns an estimate of the ATE, along with some statistical properties of the estimate. It is important to realise that the confidence intervals reported for the estimates are the confidence intervals _if we assume the model accurately describes the counterfactual_, not confidence intervals about how well the the model describes the counterfactual.\n",
    "\n",
    "In this case the package has done well in identifying the correct ATE - which is good, but the data generating process was specifically designed to meet the assumptions. Let's look at a few cases where it might fail.\n",
    "\n",
    "The first is when the effect is not simply additive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_data_2 = dg.generate_dataset_2()\n",
    "\n",
    "observed_data_2.plot.scatter(x=\"z\", y=\"y\", c=\"x\", cmap=\"rainbow\", colorbar=False)\n",
    "\n",
    "print(\"Observed ATE: {estimated_effect:.3f} ({standard_error:.3f})\".format(**estimate_uplift(observed_data_2)))\n",
    "print(\"Real ATE:  {estimated_effect:.3f} ({standard_error:.3f})\".format(**run_ab_test(dg.generate_dataset_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CausalModel(\n",
    "    \n",
    "\n",
    "\n",
    "                )\n",
    "\n",
    "cm.est_via_ols(adj=1)\n",
    "\n",
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Score\n",
    "\n",
    "The Propensity score is a estimate of how likely it is for a subject to have ended up with the treatment, given the covariates:\n",
    "\n",
    "$\\hat{p}(Z) = P(X|Z)$\n",
    "\n",
    "We can estimate this however we like, but once we have it there are a number of things we can do with it.\n",
    "\n",
    "\n",
    "## Inverse Propensity Score Weighting\n",
    "\n",
    "Remember that the problem of measuring causal inference is that we want to know the quantity $E[Y_{i}]$, but we only have access to samples from $E[Y_{i}|X=i]$.\n",
    "\n",
    "The probability of a potential outcome can be expanded to give\n",
    "\n",
    "$P(Y_{i}) = P(Y_{i}| X = i)P(X = i)$\n",
    "\n",
    "This suggests that we can estimate the true \n",
    "\n",
    "$E[Y_{i}] = E[\\frac{Y_{i}}{P(X=i|Z)}P(X=i|Z)] = E[\\frac{Y_{i}}{P(X=i|Z)}|X=i, Z]$\n",
    "\n",
    "So if we weight each point by it's inverse propensity, we can recover the potential outcomes. The result is the [inverse propensity score weight estimator](https://en.wikipedia.org/wiki/Inverse_probability_weighting):\n",
    "\n",
    "$\\Delta_{IPS} = \\frac{1}{N}\\left(\\sum_{i \\in 1} \\frac{y_{i}}{\\hat{p}(z_{i})} - \\sum_{i \\in 0} \\frac{y_{i}}{1 - \\hat{p}(z_{i})}\\right)$\n",
    "\n",
    "Let's see how it does one of our previous datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_data_1 = dg.generate_dataset_1()\n",
    "\n",
    "observed_data_1.plot.scatter(x=\"z\", y=\"y\", c=\"x\", cmap=\"rainbow\", colorbar=False)\n",
    "\n",
    "print(\"Observed ATE: {estimated_effect:.3f} ({standard_error:.3f})\".format(**estimate_uplift(observed_data_1)))\n",
    "print(\"Real ATE:  {estimated_effect:.3f} ({standard_error:.3f})\".format(**run_ab_test(dg.generate_dataset_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can estimate the propensity using the `CausalInference` package's methods `est_propensity_s` or `est_propensity`, which uses logistic regression on the covariate to estimate propensity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CausalModel(\n",
    "    \n",
    "\n",
    "                )\n",
    "\n",
    "cm.est_propensity_s()\n",
    "\n",
    "propensity = cm.propensity[\"fitted\"]\n",
    "\n",
    "df = observed_data_1\n",
    "\n",
    "# define a new column ips to compute the inverse propensity score\n",
    "df[\"ips\"] = \n",
    "\n",
    "# define a new column ipsw to compute the weighted point by its inverse propensity\n",
    "# \\frac{Y_{i}}{P(X=i|Z)}\n",
    "df[\"ipsw\"] = \n",
    "\n",
    "# calculate \\Delta_{IPS}\n",
    "ipse = \n",
    "\n",
    "ipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does well in our situation - by is very dependent on how good our estimate of the propensity score is - for the data generator we're using for this example the relationship can be described well by plain logistic regression. If we tried to estimate the propensity using, say, `sklean's` logistic regression function, which by default uses regularization, we would have got the wrong answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lg = LogisticRegression()\n",
    "X = df.z.values.reshape(-1,1)\n",
    "y = df.x.values\n",
    "lg.fit(X,y)\n",
    "\n",
    "propensity = lg.predict_proba(X)[:,1]\n",
    "\n",
    "df[\"ips\"] = np.where(\n",
    "    df.x == 1, \n",
    "    1 / propensity,\n",
    "    1 / (1 - propensity))\n",
    "df[\"ipsw\"] = df.y * df.ips\n",
    "\n",
    "ipse = (\n",
    "      df[df.x == 1][\"ipsw\"].sum() \n",
    "    - df[df.x == 0][\"ipsw\"].sum()\n",
    ") / df.shape[0]\n",
    "\n",
    "ipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does better than our naive estimator, but is not correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconfoundedness and the Propensity Score \n",
    "\n",
    "In the previous sections, we assumed that the outcomes and the treatment were independent given our covariates:\n",
    "\n",
    "$Y_{1}, Y_{0} \\ci X \\, | \\,Z$\n",
    "\n",
    "We can also assume something slightly stronger: that the outcomes are independent of the treatment, conditioned on the probability of the propensity:\n",
    "\n",
    "$Y_{1}, Y_{0} \\ci X \\, | \\,\\hat{p}(Z)$\n",
    "\n",
    "With this assumption, we potentially reduce the dimensionality of the confounding variables. This allows us to perform several techniques which may not work in higher dimensional settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Structure of Causal Inference\n",
    "\n",
    "Hopefully by this point, you will have realised the importance of the ignorability assumption\n",
    "\n",
    "$Y_{1}, Y_{0} \\ci X \\, | \\,Z$\n",
    "\n",
    "What I haven't talked about is how we choose $Z$ so that this is true. Ultimately this needs to come from domain knowledge about the system being studied. There are a set of powerful tools called [Causal Graphical Models](https://en.wikipedia.org/wiki/Causal_graph) which allow you to encode knowledge about the system being studied is a graphical model of the system and to reason about conditional independence assumptions like the one above.\n",
    "\n",
    "Another question this post might raise is whether the only way to make causal inferences is through adjusting for confounding variables. It isn't - in a [later post](http://www.degeneratestate.org/posts/2018/Sep/03/causal-inference-with-python-part-3-frontdoor-adjustment/) I look at another technique you can use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
